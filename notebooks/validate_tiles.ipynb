{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import shutil, os, sys, glob\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xval_set_0 103 103\n",
      "103 (300, 300)\n",
      "103 (300, 300)\n",
      "[[ 591286  157805   83116  105235]\n",
      " [ 166685 2353664  116372  332565]\n",
      " [  39671   38883  672671   43403]\n",
      " [ 214771  336653  273722 3743498]]\n",
      "xval_set_1 103 103\n",
      "103 (300, 300)\n",
      "103 (300, 300)\n",
      "[[ 538482  186045   42364  111544]\n",
      " [ 232164 2486072   94418  477906]\n",
      " [  34726   61132  480638   53836]\n",
      " [ 147286  327531  126161 3869695]]\n",
      "xval_set_2 102 102\n",
      "102 (300, 300)\n",
      "102 (300, 300)\n",
      "[[ 566997  214553   28934   87942]\n",
      " [ 148719 2641193   53538  415592]\n",
      " [  79188  109450  410191   74153]\n",
      " [ 201239  665682  119380 3363249]]\n",
      "xval_set_3 102 102\n",
      "102 (300, 300)\n",
      "102 (300, 300)\n",
      "[[ 261106  159883   10308   45608]\n",
      " [ 142958 2692882   72331  329618]\n",
      " [  19227   65445  415380   81486]\n",
      " [  62734  489090   74684 4257260]]\n",
      "xval_set_4 103 103\n",
      "103 (300, 300)\n",
      "103 (300, 300)\n",
      "[[ 878559  154835   50198  131835]\n",
      " [ 234044 2188755  130447  403047]\n",
      " [  56352   18642  518633   77749]\n",
      " [ 295977  282848  135599 3712480]]\n",
      "[[ 2836430   873121   214920   482164]\n",
      " [  924570 12362566   467106  1958728]\n",
      " [  229164   293552  2497513   330627]\n",
      " [  922007  2101804   729546 18946182]]\n"
     ]
    }
   ],
   "source": [
    "datasets = ['xval_set_0',\n",
    "            'xval_set_1',\n",
    "            'xval_set_2',\n",
    "            'xval_set_3',\n",
    "            'xval_set_4',\n",
    "          ]\n",
    "appendage = '_1024'\n",
    "size = 300\n",
    "\n",
    "cfmats = []\n",
    "for ds in datasets:\n",
    "    predictions = sorted(glob.glob('/home/nathan/histo-seg/semantic-pca/analysis_segnet_basic/{}/*.png'.format(ds+appendage)))\n",
    "    annotations = sorted(glob.glob('/home/nathan/histo-seg/semantic-pca/data/{}/val/mask/*.png'.format(ds)))\n",
    "    \n",
    "    print ds, len(predictions), len(annotations)\n",
    "    \n",
    "    preds = []\n",
    "    annos = []\n",
    "    for predx, annox in zip(predictions, annotations):\n",
    "#         predx = predictions[0]\n",
    "#         annox = annotations[0]\n",
    "        preds.append(cv2.imread(predx,-1))\n",
    "        annos.append(cv2.resize(cv2.imread(annox,-1), dsize=(size,size), interpolation=cv2.INTER_NEAREST))\n",
    "        \n",
    "    print len(preds), preds[0].shape#, preds[0].ravel().shape()\n",
    "    print len(preds), annos[0].shape#, annos[0].ravel().shape()\n",
    "    \n",
    "    predimg = np.hstack([pimg.ravel() for pimg in preds])\n",
    "    annoimg = np.hstack([aimg.ravel() for aimg in annos])\n",
    "    cfmat = confusion_matrix(annoimg, predimg)\n",
    "    print cfmat\n",
    "    cfmats.append(cfmat)\n",
    "\n",
    "cfmat_total = np.sum(cfmats, axis=0)\n",
    "print cfmat_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xval_set_0 103 103\n",
      "xval_set_1 103 103\n",
      "xval_set_2 102 102\n",
      "xval_set_3 102 102\n",
      "xval_set_4 103 103\n",
      "513 (300, 300)\n",
      "513 (300, 300)\n",
      "\t0 0.921032142084\n",
      "\t1 0.856641087286\n",
      "\t2 0.950944011263\n",
      "\t3 0.858677149664\n",
      "\t0.793647195148\n"
     ]
    }
   ],
   "source": [
    "datasets = ['xval_set_0',\n",
    "            'xval_set_1',\n",
    "            'xval_set_2',\n",
    "            'xval_set_3',\n",
    "            'xval_set_4',\n",
    "          ]\n",
    "appendage = '_1024'\n",
    "size = 300\n",
    "\n",
    "jaccards = []\n",
    "preds = []\n",
    "annos = []\n",
    "for ds in datasets:\n",
    "    predictions = sorted(glob.glob('/home/nathan/histo-seg/semantic-pca/analysis_segnet_basic/{}/*.png'.format(ds+appendage)))\n",
    "    annotations = sorted(glob.glob('/home/nathan/histo-seg/semantic-pca/data/{}/val/mask/*.png'.format(ds)))\n",
    "    \n",
    "    print ds, len(predictions), len(annotations)\n",
    "    \n",
    "#     preds = []\n",
    "#     annos = []\n",
    "    for predx, annox in zip(predictions, annotations):\n",
    "#         predx = predictions[0]\n",
    "#         annox = annotations[0]\n",
    "        preds.append(cv2.imread(predx,-1))\n",
    "        annos.append(cv2.resize(cv2.imread(annox,-1), dsize=(size,size), interpolation=cv2.INTER_NEAREST))\n",
    "        \n",
    "print len(preds), preds[0].shape#, preds[0].ravel().shape()\n",
    "print len(preds), annos[0].shape#, annos[0].ravel().shape()\n",
    "\n",
    "predimg = np.hstack([pimg.ravel() for pimg in preds])\n",
    "annoimg = np.hstack([aimg.ravel() for aimg in annos])\n",
    "\n",
    "for k in [0,1,2,3]:\n",
    "    anno_ = annoimg==k\n",
    "    pred_ = predimg==k\n",
    "    print '\\t', k, jaccard_similarity_score(anno_, pred_)\n",
    "\n",
    "jaccard = jaccard_similarity_score(annoimg, predimg)\n",
    "print '\\t',jaccard\n",
    "jaccards.append(jaccard)\n",
    "\n",
    "# cfmat_total = np.sum(cfmats, axis=0)\n",
    "# print cfmat_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89677499999999999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.921, 0.8566, 0.9509, 0.8586])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
